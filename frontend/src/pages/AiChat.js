import React, { useState, useRef, useEffect } from 'react';
import '../css/AiChat.css';
import '../css/ai-chart.css';

const AiChat = () => {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);
  const [language, setLanguage] = useState('english');
  const [isRecording, setIsRecording] = useState(false);
  const [mediaRecorder, setMediaRecorder] = useState(null);
  const [audioBlob, setAudioBlob] = useState(null);
  const [isSpeechRecording, setIsSpeechRecording] = useState(false);
  const [recordedText, setRecordedText] = useState('');
  const messagesEndRef = useRef(null);
  const recognitionRef = useRef(null);

  const translations = {
    english: {
      title: 'AI Assistant',
      emptyTitle: 'How can I help you today?',
      emptySubtitle: 'Ask me anything about agriculture, farming, or any other topic.',
      placeholder: 'Type your message...',
      send: 'Send',
      error: 'Sorry, something went wrong. Please try again.'
    },
    tamil: {
      title: 'AI ‡Æâ‡Æ§‡Æµ‡Æø‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç',
      emptyTitle: '‡Æá‡Æ©‡Øç‡Æ±‡ØÅ ‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æé‡Æ™‡Øç‡Æ™‡Æü‡Æø ‡Æâ‡Æ§‡Æµ ‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡ØÅ‡ÆÆ‡Øç?',
      emptySubtitle: '‡Æµ‡Æø‡Æµ‡Æö‡Ææ‡ÆØ‡ÆÆ‡Øç, ‡Æ™‡Æ£‡Øç‡Æ£‡Øà ‡ÆÖ‡Æ≤‡Øç‡Æ≤‡Æ§‡ØÅ ‡Æµ‡Øá‡Æ±‡ØÅ ‡Æé‡Æ®‡Øç‡Æ§ ‡Æ§‡Æ≤‡Øà‡Æ™‡Øç‡Æ™‡Æø‡Æ≤‡ØÅ‡ÆÆ‡Øç ‡Æé‡Æ©‡Øç‡Æ©‡Æø‡Æü‡ÆÆ‡Øç ‡Æï‡Øá‡Æ≥‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç.',
      placeholder: '‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡Æø‡ÆØ‡Øà ‡Æ§‡Æü‡Øç‡Æü‡Æö‡Øç‡Æö‡ØÅ ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ‡Æµ‡ØÅ‡ÆÆ‡Øç...',
      send: '‡ÆÖ‡Æ©‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ',
      error: '‡ÆÆ‡Æ©‡Øç‡Æ©‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç, ‡Æè‡Æ§‡Øã ‡Æ§‡Æµ‡Æ±‡ØÅ ‡Æ®‡Æü‡Æ®‡Øç‡Æ§‡Æ§‡ØÅ. ‡ÆÆ‡ØÄ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡ÆÆ‡ØÅ‡ÆØ‡Æ±‡Øç‡Æö‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.'
    }
  };

  const t = translations[language];

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
      const recognition = new SpeechRecognition();
      recognition.lang = language === 'tamil' ? 'ta-IN' : 'en-US';
      recognition.continuous = true;
      recognition.interimResults = false;
      
      recognition.onresult = event => {
        const transcript = Array.from(event.results)
          .map(result => result[0].transcript)
          .join(' ');
        setRecordedText(transcript);
      };
      
      recognition.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        if (event.error !== 'aborted') {
          setIsSpeechRecording(false);
        }
      };
      
      recognition.onend = () => {
        setIsSpeechRecording(false);
      };
      
      recognitionRef.current = recognition;
    }
    
    return () => {
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (e) {
          // Ignore errors on cleanup
        }
      }
    };
  }, [language]);

  const handleSend = async (voiceMessage = null) => {
    if (!input.trim() && !voiceMessage) return;

    const userMessage = { 
      role: 'user', 
      content: input || (language === 'tamil' ? '‡Æï‡ØÅ‡Æ∞‡Æ≤‡Øç ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡Æø' : 'Voice Message'),
      audio: voiceMessage || null
    };
    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setAudioBlob(null);
    setLoading(true);

    try {
      const formData = new FormData();
      if (voiceMessage) {
        formData.append('audio', voiceMessage, 'voice-message.wav');
        formData.append('type', 'voice');
      } else {
        formData.append('message', input);
        formData.append('type', 'text');
      }

      const response = await fetch('http://localhost:5000/api/ai/chat', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${localStorage.getItem('token')}`
        },
        body: formData
      });

      const data = await response.json();
      const aiMessage = { role: 'assistant', content: data.response };
      setMessages(prev => [...prev, aiMessage]);
    } catch (error) {
      const errorMessage = { role: 'assistant', content: t.error };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setLoading(false);
    }
  };

  const handleKeyPress = (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  const handleVoiceClick = async () => {
    if (isRecording) {
      // Stop recording
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
      }
      setIsRecording(false);
    } else {
      // Start recording
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const recorder = new MediaRecorder(stream);
        const chunks = [];

        recorder.ondataavailable = (e) => {
          if (e.data.size > 0) {
            chunks.push(e.data);
          }
        };

        recorder.onstop = () => {
          const blob = new Blob(chunks, { type: 'audio/wav' });
          setAudioBlob(blob);
          handleSend(blob);
          stream.getTracks().forEach(track => track.stop());
        };

        recorder.start();
        setMediaRecorder(recorder);
        setIsRecording(true);
        
      } catch (error) {
        console.error('Error accessing microphone:', error);
        alert('Microphone access denied. Please allow microphone access.');
      }
    }
  };

  const handleSpeechToText = () => {
    if (!recognitionRef.current) {
      alert(language === 'tamil' ? '‡Æá‡Æ®‡Øç‡Æ§ ‡Æâ‡Æ≤‡Ææ‡Æµ‡Æø‡ÆØ‡Æø‡Æ≤‡Øç ‡Æï‡ØÅ‡Æ∞‡Æ≤‡Øç ‡Æâ‡Æ≥‡Øç‡Æ≥‡ØÄ‡Æü‡ØÅ ‡ÆÜ‡Æ§‡Æ∞‡Æø‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Æµ‡Æø‡Æ≤‡Øç‡Æ≤‡Øà.' : 'Voice input not supported in this browser.');
      return;
    }
    
    if (isSpeechRecording) {
      try {
        recognitionRef.current.stop();
      } catch (e) {
        console.error('Error stopping recognition:', e);
      }
      setIsSpeechRecording(false);
    } else {
      setRecordedText('');
      setIsSpeechRecording(true);
      
      try {
        recognitionRef.current.start();
      } catch (e) {
        console.error('Error starting recognition:', e);
        setIsSpeechRecording(false);
      }
    }
  };

  const addRecordedText = () => {
    if (recordedText) {
      setInput(prev => prev + (prev ? ' ' : '') + recordedText);
      setRecordedText('');
    }
  };

  const cancelRecording = () => {
    if (isSpeechRecording && recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (e) {
        console.error('Error stopping recognition:', e);
      }
    }
    setIsSpeechRecording(false);
    setRecordedText('');
  };

  return (
    <div className="ai-chat-container">
      <div className="chat-header">
        <h2>{t.title}</h2>
        <button
          onClick={() => setLanguage(language === 'english' ? 'tamil' : 'english')}
          className="lang-btn"
        >
          {language === 'english' ? '‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç' : 'English'}
        </button>
      </div>

      <div className="chat-messages">
        {messages.length === 0 && (
          <div className="empty-state">
            <h3>{t.emptyTitle}</h3>
            <p>{t.emptySubtitle}</p>
          </div>
        )}

        {messages.map((msg, index) => (
          <div key={index} className={`message ${msg.role}`}>
            <div className="message-content">
              {msg.audio && msg.audio instanceof Blob ? (
                <div className="voice-message-display">
                  <p className="voice-label">üé§ {msg.content}</p>
                  <audio controls>
                    <source src={URL.createObjectURL(msg.audio)} type="audio/wav" />
                  </audio>
                </div>
              ) : (
                msg.content
              )}
            </div>
          </div>
        ))}

        {loading && (
          <div className="message assistant">
            <div className="message-content typing">
              <span></span><span></span><span></span>
            </div>
          </div>
        )}

        <div ref={messagesEndRef} />
      </div>

      <div className="chat-input-container">
        <textarea
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyPress={handleKeyPress}
          placeholder={t.placeholder}
          rows="1"
        />
        <button 
          className={`voice-btn speech-to-text ${isSpeechRecording ? 'recording' : ''}`} 
          onClick={handleSpeechToText}
          title={isSpeechRecording ? (language === 'tamil' ? '‡Æ®‡Æø‡Æ±‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ' : 'Stop') : (language === 'tamil' ? '‡Æ™‡Øá‡Æö‡Øç‡Æö‡ØÅ ‡Æâ‡Æ∞‡Øà‡ÆØ‡Ææ‡Æï' : 'Speech to Text')}
        >
          {isSpeechRecording ? '‚èπÔ∏è' : 'üé§'}
        </button>
        <button 
          className={`voice-btn ${isRecording ? 'recording' : ''}`} 
          onClick={handleVoiceClick}
          title={isRecording ? (language === 'tamil' ? '‡Æ®‡Æø‡Æ±‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ' : 'Stop Recording') : (language === 'tamil' ? '‡ÆÜ‡Æü‡Æø‡ÆØ‡Øã ‡Æ™‡Æ§‡Æø‡Æµ‡ØÅ' : 'Voice Input')}
        >
          {isRecording ? '‚èπÔ∏è' : 'üéôÔ∏è'}
        </button>
        <button onClick={handleSend} disabled={!input.trim() || loading}>
          {t.send}
        </button>
        
        {recordedText && (
          <div className="recorded-text-preview">
            <span>{recordedText}</span>
            <button type="button" onClick={addRecordedText} className="add-text-btn">‚úÖ {language === 'tamil' ? '‡Æö‡Øá‡Æ∞‡Øç' : 'Add'}</button>
            <button type="button" onClick={cancelRecording} className="cancel-text-btn">‚ùå</button>
          </div>
        )}
      </div>
    </div>
  );
};

export default AiChat;
